{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Electrocardiograms (ECG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/9/9e/SinusRhythmLabels.svg' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "üßëüèª‚Äçüè´ We saw in the first challenge that **Recurrent Neural Networks are well designed to work with sequence prediction problems**: based on an observed sequence of data, RNNs are used to predict what will happen next (predicting the next value(s) of a temperature, a stock price, ... $ \\rightarrow $ ***regression task***).\n",
    "\n",
    "üëâ Let's see a different way to use RNNs. Instead of predicting a value that occurs after the observed sequence, we will ***classify the entire sequence*** itself, as if the whole sequence corresponds to a given category. \n",
    "\n",
    "üéØ Exercise objectives:\n",
    "- Discover a new type of application with temporal data: classification (we will classify heartbeats ‚ù§Ô∏è)\n",
    "- Try different RNN architectures.\n",
    "\n",
    "_PS: No need to use Google Colab_ ‚ùå"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The ECG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "* The data corresponds to electrocardiograms (ECG), which are basically heartbeats.\n",
    "    - Each sequence is therefore a sequence of amplitudes. \n",
    "    - These ECGs are often used to observe heart malfunctions! \n",
    "* In this dataset, there are 87554 heartbeats and each of them corresponds to a heartbeat type, ranging from 0 to 4:\n",
    "    - 0 : Normal beat\n",
    "    - 1 : Supraventricular\n",
    "    - 2 : Ventricular\n",
    "    - 3 : Fusion\n",
    "    - 4 : Beats that cannot be classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) üéÅ Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Loading X\n",
    "response = requests.get('https://wagon-public-datasets.s3.amazonaws.com/06-DL/ECG_X.npy')\n",
    "response.raise_for_status()\n",
    "X = np.load(io.BytesIO(response.content), allow_pickle=True).tolist()\n",
    "\n",
    "# Loading y\n",
    "response = requests.get('https://wagon-public-datasets.s3.amazonaws.com/06-DL/ECG_y.npy')\n",
    "response.raise_for_status()\n",
    "y = np.load(io.BytesIO(response.content), allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) üéÅ Visualizing some ECGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéÅ We gave you a piece of Python code to plot one ECG for each category in the dataset \n",
    "\n",
    "üë©üèª‚Äç‚öïÔ∏è *Run the following cell* to catch a glimpse about how an ECG looks like for each category and then move forward to section `(1.3) Padding the sequences` once that you have visualized these ECG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# ------------------------- #\n",
    "#      Some colormaps       #\n",
    "# ------------------------- #\n",
    "\n",
    "name = \"tab20c\"\n",
    "cmap = get_cmap(name)  # type: matplotlib.colors.ListedColormap\n",
    "colors_list = cmap.colors\n",
    "\n",
    "\n",
    "# ------------------------- #\n",
    "#      Some ECG             #\n",
    "# ------------------------- #\n",
    "\n",
    "fix, axs = plt.subplots(5,5, figsize=(15,10))\n",
    "\n",
    "for i in range(5): # Five examples per category\n",
    "    for j in range(5): # Iterating over the 5 categories\n",
    "        idx_C = np.argwhere(np.array(y) == j)  # Collecting the indexes of all the heartbeats of category j\n",
    "        axs[i,j].plot(X[idx_C[i][0]], label=f'Category {j}', c=colors_list[j+3]) # Plotting the ECG\n",
    "        # Some cosmetic tricks down below\n",
    "        if i == 0:\n",
    "            axs[i,j].legend(loc='upper center')\n",
    "            if j ==0:\n",
    "                axs[i,j].set_xlabel('Time')\n",
    "                axs[i,j].set_ylabel('ECG Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) üíª Padding the sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üïµüèª‚Äç‚ôÇÔ∏è You have (probably?) noticed that each sequence, i.e. each ECG, has a different length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Plot the distribution of the sequences' lengths in the dataset to confirm this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüè´ Remember that Neural Networks are fed with tensors, batch per batch. The shape of these tensors is the following:\n",
    "\n",
    "\n",
    ">`(# SEQUENCES, # OBSERVATIONS per sequence, # FEATURES per observation)`\n",
    "\n",
    "- `# SEQUENCES` = $87554$ sequences\n",
    "- `# OBSERVATIONS per sequence` = ‚ùóÔ∏è***the number of observations varies from one sequence to another one***‚ùóÔ∏è \n",
    "- `# FEATURES per observation` = each observation collects only $1$ feature = the amplitude of the ECG.\n",
    "\n",
    "üò∞ Such a tensor is called a ***ragged tensor***. For computational reasons, this cannot be fed into a Recurrent Neural Network. \n",
    "\n",
    "üí° RNNs need to be fed with proper tensors. For this reason, you need to \"***fill in the blanks of each sequence***\". Using [üìö **`pad_sequences`**](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences), each sequence will be filled with fake values. The resulting sequences will all be the same length.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/tensors_in_rnn.png\" alt=\"Tensors in RNN\" width=\"500\" height=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë®üèª‚Äçüè´ How will the Recurrent Neural Network know that a zero is a fake value used as a pad for computational reasons? There is a layer called **`Masking`** layer which will inform the RNN to ignore the fake values. \n",
    "\n",
    "üí° Best practices when manipulating `pad_sequences`:\n",
    "* It is better to pad the \"missing values\" at the end of the sequences with the argument `padding = 'post'`\n",
    "* You should use a padding value that doesn't make sense for the problem you are tackling. It will be easier for the Network to distinguish the padding value from the other values. _For example, a heartbeat can't be negative_, therefore you could use a padding value `value = -1` here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Apply the üìö [**`pad_sequences`**](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) function on X.\n",
    "\n",
    "- Don't forget the following arguments `dtype`, `padding = 'post'` and `value = -1`\n",
    "- Store the padded sequences in a variable called `X_pad`\n",
    "- And print the first padded sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What version of Tensorflow do you have ? \n",
    "!pip freeze | grep tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING, the way to import pad_sequences will differ depending on your tensorflow version\n",
    "# Check the Tensorflow documentation\n",
    "\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ If you padded properly, the shape of `X_pad` should be equal to $ (87554, 187) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "print(f\"X_pad.shape = {X_pad.shape}\")\n",
    "\n",
    "result = ChallengeResult('X_pad_shape',\n",
    "                         X_pad_shape = X_pad.shape)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è We are missing one dimension, the last one (corresponding to the number of features per observation)\n",
    "\n",
    "‚ùì **Question** ‚ùì To fix this issue, expand the last dimension using `expand_dims` function from `Numpy` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_pad.shape == (87554, 187, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) üíª  Encoding the categorical targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c42605d020fd51885437f4af3cf10cebbeafc9bb"
   },
   "source": [
    "‚ùì **Question** ‚ùì The labels `y` have to be converted to one-hot-encoded categories. Transform `y` into categories using the appropriate Keras function and store the result into a variable called `y_cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) üíª  RNN modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ae5108c9741b85f0f599cce51daf99df4733ed1"
   },
   "source": [
    "‚ùì **Question** ‚ùì Split your dataset (the electrocardiograms) between a train and test set (80/20 ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ddf1e7b397de3c413fc991945d2d7f09df67da1",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) üíª  GRU and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ In comparison with the previous challenge, each sequence comprises many observations (187 units of time), and your intuition should tell you that ALL of them matter to detect heart diseases (not just the most \"recent\" ones). \n",
    "\n",
    "üöÄ The **LSTM (= Long Short Term Memory)** or the **GRU (= Gated Recurrent Unit)** model, with their ability to *avoid the vanishing gradient problem*, should be preferred over a SimpleRNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4de23b85abe34a726eab268171da0e827bafa35"
   },
   "source": [
    "‚ùì **Question (RNN architecture)** ‚ùì \n",
    "* Write a model that has the following layers:\n",
    "    - a Masking layer whose `mask_value` corresponds to the value you decided to pad your data with (it is probably a negative value as suggested) - this layer will simply tell the network not to take into account the computation artifact\n",
    "    - two stacked `GRU` layers with 20 units each, and the `tanh` as the activation function\n",
    "    - a dense layer with 50 units\n",
    "    - a dropout layer with 20% drop\n",
    "    - a last (predictive) dense layer.\n",
    "* Print the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Training)** ‚ùì Compile and train your model. \n",
    "\n",
    "<u>Warning:</u> You will notice that it can take a very long time per epoch, even with GPUs. RNNs are, by nature, harder to distribute than CNNs. Indeed, GPUs work best when `trainable_params` is large (which is not the case here), or when `batch_size` is large.\n",
    "\n",
    "- To reduce the duration of each epoch, use a larger batch size (e.g 128)\n",
    "\n",
    "- Use also very small patience equal to 1 should be sufficient. This is because you have a lot of sequences and thus, many optimizations per epochs, even with a relatively large `batch_size`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Evaluation)** ‚ùì Evaluate your model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) üíª Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüè´ ***In a classification task, a baseline model is to predict the most frequent class of the training set for all the elements in the test set.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what is the accuracy of a baseline model which would predict, for each ECG in `y_test`, the most probable category in `y_train` ? \n",
    "\n",
    "* üéÅ We wrote down below the code to compute the baseline accuracy of a multiclass classification task for you.\n",
    "    * üßëüèª‚Äçüéì Make sure you understand the code by running the cells sequentially\n",
    "* üïµÔ∏è‚Äç‚ôÄÔ∏è Compare the baseline accuracy with the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a reminder, here is y_train \"encoded\"\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the occurencies per heartbeat category in the train set\n",
    "occurencies_per_heartbeat_category_train = np.sum(y_train, axis=0)\n",
    "occurencies_per_heartbeat_category_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see that the first category is the most frequent one in the train set\n",
    "most_frequent_category_train = np.argmax(occurencies_per_heartbeat_category_train)\n",
    "most_frequent_category_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can compute the occurencies per heartbeat category in the test set as well\n",
    "occurencies_per_heartbeat_category_test = np.sum(y_test, axis=0)\n",
    "occurencies_per_heartbeat_category_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict the most_frequent_category_train category for all the ECG in the test set\n",
    "number_of_correct_predictions = occurencies_per_heartbeat_category_test[most_frequent_category_train]\n",
    "number_of_correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Evaluating\" the baseline model: in the test set, a baseline model will always predict\n",
    "# the most frequent class found in the train set\n",
    "baseline_accuracy = number_of_correct_predictions/len(y_test)\n",
    "print(f'Baseline accuracy = {round(baseline_accuracy,3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëÜ Basically, the RNN that we designed earlier turns out to be as good/bad as a baseline model that predicts the most present category... \n",
    "\n",
    "üïµüèª Let's try to deep dive into the predictions of the RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** ‚ùì Use the *predict* function to check what categories are predicted by the RNN model. Compare the distribution of the predictions with the distributions of the classes in the training set. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) üìö Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§® The RNN model predicts frequencies that are extremely close to the original distribution of the heartbeats in the training set... Why is that?\n",
    "\n",
    "* The RNN was trained on a quite ***imbalanced dataset***. We could rebalance the dataset by downsampling the most represented category (normal heartbeats) and oversampling the under-represented categories... But that is not the focus of this chapter on RNN :)\n",
    "* ***Neural networks require bigger datasets***. The current dataset is *too small* for Neural Networks to learn noticeable facts from it.\n",
    "* Predicting the category of an ECG for one patient it not an easy task. ***We should have multiple ECGs for each patient to help the RNN learn the patterns of what a \"healthy ECG\" is***. Unfortunately, in this dataset, there is only ***one*** heartbeat per patient.\n",
    "\n",
    "‚ùå Do not try to improve the results here. \n",
    "\n",
    "üßëüèª‚Äçüè´ One lesson that we have been teaching you and that we are going to repeat here again and again:\n",
    "* **Don't be satisfied with any \"good\" accuracy unless you have compared your model to a baseline model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "üèÅ Congratulations üèÅ\n",
    "\n",
    "\n",
    "üíæ Don't forget to push your code\n",
    "\n",
    "Follow the usual procedure on your terminal in the `06-Deep-Learning/04-Recurrent-Neural-Networks/02-Classify-Electrocardiograms` Classification folder:\n",
    "* *git add classify_electrocardiograms.ipynb*\n",
    "* *git commit -m \"I love RNN for ECG\"* or whatever meaningful message you want\n",
    "* *git push origin master*\n",
    "\n",
    "\n",
    "üöÄ It is time to move on to the *Predict Temperature* challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
